### GENERAL CONFIG ###

# unique identifier for metrics calculation experiment
exp_id: "deuce_probabilistic_metrics"
logging_level: INFO
# debugging flag, so that we don't try and go trough all the samples
# set to False or integer (num of samples to pick)
debugging: False
# If set to false, existing contingency tables will simply be used to compute metric values
accumulate: True
# number of chunks to divide the timestamps in for parallelization
# for NO parallelization set to 0
# otherwise set to a positive integer smalller than the number of test samples
# recommended is to set equal or bigger to the number of available processing units
n_chunks: 500
n_workers: 20

### PATH RELATED CONFIG ### 
path: 
    root: "data/metrics/{id}"
    # template path to the files recording the final values of metrics that have been calculated
    metrics: "data/metrics/{id}/{metric}_{method}.nc"
    # template path for the npy file storing contigency tables recording partial metric calculations
    states: "data/metrics/{id}/metric_states/state_{method}_{metric}.dump"
    # the path to the text file containing a list of timestamps to calculate metrics on
    timestamps: "datelists/fmi_rainy_days_bbox_predict.txt"
    # the path to the CSV file recording which metrics have been calculated
    done: "data/metrics/{id}/done_{id}.csv"
    # where to save copy of the input config
    config_copy: "data/metrics/{id}/{id}_config.yaml"
    # the path to the file containing logging output for the experiment
    logging: "data/metrics/{id}/{id}.log"


### PREDICTION RELATED CONFIG ### 

# which prediction method name to calculate the metrics on
# and path to the predictions
methods:
  bcnn:
    path: data/deuce_nowcasts/deuce-combined.hdf5
  linda-p:
    path: data/baseline_nowcasts/linda-p.hdf5
  steps:
    path: data/baseline_nowcasts/steps.hdf5
  #bcnn_1:
  #  path: /data/PINCAST/bayesian_rainnet/nowcasts/bcnn_2nd_preds_combined.hdf5
# measurement path
measurements:
  name: measurements
  path: data/baseline_nowcasts/measurements.hdf5

preprocessing:
  convert_mmh: false
  threshold : 8.0
  zerovalue : -10.0
  
# leadtimes to calculate the metrics for as units of 5 minutes
n_leadtimes: 12
# if set to True, will mask all predictions the same, using "logical and" operation
common_mask: True

### METRICS RELATED CONFIG ###
metrics: 
  CRPS:
    init_kwargs:  
      leadtimes : [1,2,3,4,5,6,7,8,9,10,11,12]
  RANK_HISTOGRAM:
    init_kwargs:
      # leadtimes for which to calculate histograms
      leadtimes : [1,3,6,12]
      # ensemble members in ensemble predictions = number of bins in histograms
      num_ens_member : 48
      # minimum rainrate to be classified as rain occuring
      X_min : 0.1
  ROC:
    init_kwargs:
      # leadtimes for which to calculate
      leadtimes : [1,3,6,12]
      # thresholds 
      thresholds: [20,25,35,45]
      # which metric to calculate
      roc_kwargs: 
        n_prob_thrs: 10
  RELDIAG:
    init_kwargs:
      # leadtimes for which to calculate
      leadtimes : [1,3,6,12]
      # thresholds 
      thresholds: [20,25,35,45]
      # which metric to calculate
      reldiag_kwargs: 
        n_bins: 10
        min_count: 10
